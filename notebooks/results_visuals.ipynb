{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import WavPool.training.plot_results as plots\n",
    "from WavPool.training.training_metrics import TrainingMetrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"../results/naive_params/\"\n",
    "extra_metrics = [TrainingMetrics.accuracy,\n",
    "                TrainingMetrics.auc_roc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_experiment(network, dataset): \n",
    "    all_experiments = os.listdir(results_path)\n",
    "    exp_dir = [exp for exp in all_experiments if (network in exp) and (dataset in exp)][0]\n",
    "    return exp_dir\n",
    "\n",
    "def read_history_json(network, dataset): \n",
    "    experiment = _find_experiment(network, dataset)\n",
    "    history_path = f\"{results_path}{experiment}/history.json\"\n",
    "    with open(history_path, 'r') as path: \n",
    "        history = json.load(path)\n",
    "    runs = []\n",
    "    for key in history.keys(): \n",
    "        hist = pd.DataFrame(history[key]).astype(float)\n",
    "        runs.append(hist)\n",
    "    return runs\n",
    "\n",
    "\n",
    "def read_param_json(network, dataset):\n",
    "    experiment = _find_experiment(network, dataset)\n",
    "    history_path = f\"{results_path}{experiment}/parameter_history.json\"\n",
    "    with open(history_path, 'r') as path: \n",
    "        history = json.load(path)\n",
    "    num_params = history['num_parameters']\n",
    "    inference_time = history['inference_timing']\n",
    "    training_time = history['training_timing']\n",
    "\n",
    "    return num_params, inference_time, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"CNN\", \"VanillaMLP\", \"WavPool\"]\n",
    "colorway = [\"yellowgreen\", 'burlywood', \"royalblue\"]\n",
    "markers = [\"o\", 's', '^']\n",
    "datasets = [\"FashionMNIST\", \"_MNIST\", \"CIFAR\"]\n",
    "\n",
    "\n",
    "for dataset in datasets: \n",
    "    n_subplots = len(extra_metrics) + 1\n",
    "    fig, subplots = plt.subplots(nrows=n_subplots, ncols=1, figsize=(6, 2.5*n_subplots))\n",
    "\n",
    "    for model, color, marker in zip(models, colorway, markers): \n",
    "        histories = read_history_json(model, dataset)\n",
    "        label = model\n",
    "\n",
    "        for metric_index, metrics in enumerate(extra_metrics):\n",
    "\n",
    "            training = [history[f\"train_{metrics.__name__}\"] for history in histories]\n",
    "            val = [history[f\"val_{metrics.__name__}\"] for history in histories]\n",
    "\n",
    "            mean_training = pd.DataFrame(training).mean(axis=0)\n",
    "            std_training = pd.DataFrame(training).std(axis=0)\n",
    "\n",
    "            epochs = range(len(mean_training))\n",
    "\n",
    "            mean_val = pd.DataFrame(val).mean(axis=0)\n",
    "\n",
    "            subplots[metric_index].grid(color = 'grey', linestyle = '--', linewidth = 0.5, alpha=.6)\n",
    "\n",
    "            subplots[metric_index].plot(epochs, mean_training, label=label, color=color)\n",
    "            subplots[metric_index].fill_between(epochs,mean_training-std_training, mean_training+std_training ,alpha=0.3, color=color)\n",
    "            subplots[metric_index].plot(epochs, mean_val, linestyle='dotted', color=color)\n",
    "            subplots[metric_index].set_ylabel(metrics.__name__)\n",
    "\n",
    "\n",
    "        training = [history[f\"train_loss\"] for history in histories]\n",
    "        val = [history[f\"val_loss\"] for history in histories]\n",
    "\n",
    "        mean_training = pd.DataFrame(training).mean(axis=0)\n",
    "        std_training = pd.DataFrame(training).std(axis=0)\n",
    "        mean_val = pd.DataFrame(val).mean(axis=0)\n",
    "\n",
    "        epochs = range(len(mean_training))\n",
    "\n",
    "        metric_index = -1\n",
    "\n",
    "        subplots[metric_index].plot(epochs, mean_training, label=label, color=color)\n",
    "        subplots[metric_index].fill_between(epochs,mean_training-std_training, mean_training+std_training ,alpha=0.3, color=color)\n",
    "        subplots[metric_index].plot(epochs, mean_val, linestyle=\"dotted\", color=color)\n",
    "        subplots[metric_index].set_ylabel(\"Loss\")\n",
    "        subplots[metric_index].grid(color = 'grey', linestyle = '--', linewidth = 0.5, alpha=.6)\n",
    "\n",
    "        subplots[0].set_title(dataset.strip(\"_\"))\n",
    "    plt.xlabel(\"Epochs Before Stopping\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets: \n",
    "    num_params = []\n",
    "    inference_time = []\n",
    "    training_time = []\n",
    "    for i, model in enumerate(models): \n",
    "        params, inference, train = read_param_json(model, dataset)\n",
    "\n",
    "        num_params.append(params)\n",
    "        inference_time.append(inference)\n",
    "        training_time.append(train)\n",
    "    \n",
    "    fig, subplots = plt.subplots(nrows=3, ncols=1, figsize=(6,10))\n",
    "\n",
    "    bar_x = [i+1 for i in range(len(num_params))]\n",
    "    widths = [.75 for _ in range(len(num_params))]\n",
    "\n",
    "    subplots[0].barh(y=bar_x, width=num_params, color=colorway)\n",
    "    subplots[0].set_xlabel(\"Number Parameters\")\n",
    "    subplots[0].grid(color = 'grey', linestyle = '--', linewidth = 0.5, alpha=.6)\n",
    "\n",
    "    for model, color, inference, training in zip(models, colorway, inference_time, training_time):\n",
    "        w = .00005\n",
    "        subplots[1].hist(\n",
    "            inference, \n",
    "            bins=np.arange(min(inference), max(inference)+w, w), \n",
    "            label=model, color=color)\n",
    "        subplots[1].set_xlabel(\"Mean Single Inference Time (s)\")\n",
    "        subplots[1].grid(color = 'grey', linestyle = '--', linewidth = 0.5, alpha=.6)\n",
    "\n",
    "        w = 3.0\n",
    "        subplots[2].hist(\n",
    "            training, \n",
    "            bins=np.arange(min(training), max(training)+w, w), \n",
    "            label=model, color=color)\n",
    "\n",
    "        subplots[2].set_xlabel(\"Mean Full Training Time (s)\")\n",
    "        subplots[2].grid(color = 'grey', linestyle = '--', linewidth = 0.5, alpha=.6)\n",
    "\n",
    "    subplots[0].set_title(dataset.strip('_'))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"../results/optimize_params/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, model_names = [\"CNN\", \"VanillaMLP\", \"WavPool\"], [\"CNN\", \"MLP\", \"WavPool\"]\n",
    "colorway = [\"yellowgreen\", 'burlywood', \"royalblue\"]\n",
    "markers = [\"o\", 's', '^']\n",
    "datasets, dataset_name = [\"_MNIST\",\"FashionMNIST\", \"CIFAR\"], [\"MNIST\", \"Fashion-MNIST\", \"CIFAR-10\"]\n",
    "\n",
    "\n",
    "for dataset, dataset_name in zip(datasets, dataset_name): \n",
    "    n_subplots = len(extra_metrics) + 1\n",
    "    fig, subplots = plt.subplots(nrows=n_subplots, ncols=1, figsize=(6, 2.5*n_subplots))\n",
    "\n",
    "    for model, model_name, color, marker in zip(models, model_names, colorway, markers): \n",
    "        histories = read_history_json(model, dataset)\n",
    "        label = model\n",
    "\n",
    "        training = [history[f\"train_{TrainingMetrics.accuracy.__name__}\"] for history in histories]\n",
    "        val = [history[f\"val_{TrainingMetrics.accuracy.__name__}\"] for history in histories]\n",
    "\n",
    "        mean_training = pd.DataFrame(training).mean(axis=0)\n",
    "        std_training = pd.DataFrame(training).std(axis=0)\n",
    "\n",
    "        epochs = range(len(mean_training))\n",
    "\n",
    "        mean_val = pd.DataFrame(val).mean(axis=0)\n",
    "\n",
    "        subplots[0].grid(color = 'grey', linestyle = '--', linewidth = 0.5, alpha=.6)\n",
    "\n",
    "        subplots[0].plot(epochs, mean_training, label=model_name, color=color)\n",
    "        subplots[0].fill_between(epochs,mean_training-std_training, mean_training+std_training ,alpha=0.3, color=color)\n",
    "        subplots[0].plot(epochs, mean_val, linestyle='dotted', color=color, linewidth=4)\n",
    "        subplots[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "\n",
    "\n",
    "        training = [history[f\"train_{TrainingMetrics.auc_roc.__name__}\"] for history in histories]\n",
    "        val = [history[f\"val_{TrainingMetrics.auc_roc.__name__}\"] for history in histories]\n",
    "\n",
    "        mean_training = pd.DataFrame(training).mean(axis=0)\n",
    "        std_training = pd.DataFrame(training).std(axis=0)\n",
    "\n",
    "        epochs = range(len(mean_training))\n",
    "\n",
    "        mean_val = pd.DataFrame(val).mean(axis=0)\n",
    "\n",
    "        subplots[1].grid(color = 'grey', linestyle = '--', linewidth = 0.5, alpha=.6)\n",
    "\n",
    "        subplots[1].plot(epochs, mean_training, label=model_name, color=color)\n",
    "        subplots[1].fill_between(epochs,mean_training-std_training, mean_training+std_training ,alpha=0.3, color=color)\n",
    "        subplots[1].plot(epochs, mean_val, linestyle='dotted', color=color,linewidth=4 )\n",
    "        subplots[1].set_ylabel(\"ROC AUC\")\n",
    "\n",
    "\n",
    "        training = [history[f\"train_loss\"] for history in histories]\n",
    "        val = [history[f\"val_loss\"] for history in histories]\n",
    "\n",
    "        mean_training = pd.DataFrame(training).mean(axis=0)\n",
    "        std_training = pd.DataFrame(training).std(axis=0)\n",
    "        mean_val = pd.DataFrame(val).mean(axis=0)\n",
    "\n",
    "        epochs = range(len(mean_training))\n",
    "\n",
    "        metric_index = -1\n",
    "\n",
    "        subplots[2].plot(epochs, mean_training, label=model_name, color=color)\n",
    "        subplots[2].fill_between(epochs,mean_training-std_training, mean_training+std_training ,alpha=0.3, color=color)\n",
    "        subplots[2].plot(epochs, mean_val, linestyle=\"dotted\", color=color, linewidth=4)\n",
    "        subplots[2].set_ylabel(\"Loss\")\n",
    "        subplots[2].grid(color = 'grey', linestyle = '--', linewidth = 0.5, alpha=.6)\n",
    "\n",
    "        subplots[0].set_title(dataset_name)\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets: \n",
    "    num_params = []\n",
    "    inference_time = []\n",
    "    training_time = []\n",
    "    for i, model in enumerate(models): \n",
    "        params, inference, train = read_param_json(model, dataset)\n",
    "\n",
    "        num_params.append(params)\n",
    "        inference_time.append(inference)\n",
    "        training_time.append(train)\n",
    "    \n",
    "    fig, subplots = plt.subplots(nrows=3, ncols=1, figsize=(6,10))\n",
    "\n",
    "    bar_x = [i+1 for i in range(len(num_params))]\n",
    "    widths = [.75 for _ in range(len(num_params))]\n",
    "\n",
    "    subplots[0].barh(y=bar_x, width=num_params, color=colorway)\n",
    "    subplots[0].set_xlabel(\"Number Parameters\")\n",
    "    subplots[0].grid(color = 'grey', linestyle = '--', linewidth = 0.5, alpha=.6)\n",
    "\n",
    "    for model, color, inference, training in zip(models, colorway, inference_time, training_time):\n",
    "        w = .00005\n",
    "        subplots[1].hist(\n",
    "            inference, \n",
    "            bins=np.arange(min(inference), max(inference)+w, w), \n",
    "            label=model, color=color)\n",
    "        subplots[1].set_xlabel(\"Mean Single Inference Time (s)\")\n",
    "        subplots[1].grid(color = 'grey', linestyle = '--', linewidth = 0.5, alpha=.6)\n",
    "\n",
    "        w = 3.0\n",
    "        subplots[2].hist(\n",
    "            training, \n",
    "            bins=np.arange(min(training), max(training)+w, w), \n",
    "            label=model, color=color)\n",
    "\n",
    "        subplots[2].set_xlabel(\"Mean Full Training Time (s)\")\n",
    "        subplots[2].grid(color = 'grey', linestyle = '--', linewidth = 0.5, alpha=.6)\n",
    "\n",
    "    subplots[0].set_title(dataset.strip('_'))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Def make fractional difference \n",
    "\n",
    "frac_difference = pd.DataFrame()\n",
    "\n",
    "for dataset, dataset_name in zip([\"_MNIST\",\"FashionMNIST\", \"CIFAR\"], [\"MNIST\", \"FMNIST\", \"CIFAR-10\"]): \n",
    "\n",
    "    for model, model_name, color, marker in zip(models, model_names, colorway, markers): \n",
    "        histories = read_history_json(model, dataset)\n",
    "        \n",
    "        val = [history[f\"val_{TrainingMetrics.accuracy.__name__}\"] for history in histories]\n",
    "        mean_acc_val = pd.DataFrame(val).mean(axis=1).values[-1]\n",
    "\n",
    "\n",
    "        val = [history[f\"val_{TrainingMetrics.auc_roc.__name__}\"] for history in histories]\n",
    "        mean_auc_val = pd.DataFrame(val).mean(axis=1).values[-1]\n",
    "\n",
    "\n",
    "        val = [history[f\"val_loss\"] for history in histories]\n",
    "        mean_val = pd.DataFrame(val).mean(axis=1).values[-1]\n",
    "\n",
    "        frac_difference = frac_difference.append(pd.DataFrame({\n",
    "            \"dataset\":dataset_name, \"model\":model_name, \n",
    "            \n",
    "\"mean_val_loss\":mean_val, \n",
    "\"auc_val\":mean_auc_val, \n",
    "\"acc_val\":mean_acc_val}, index=[0])) #type: ignore\n",
    "        \n",
    "frac_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"../../LatexAutoTable/\")\n",
    "from AutoTable.table import Table\n",
    "from AutoTable.elements import Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = Table(table_columns=[])\n",
    "\n",
    "for dataset in frac_difference['dataset'].unique(): \n",
    "    subset = frac_difference[frac_difference['dataset']==dataset]\n",
    "    wavpool = subset[subset['model']=='WavPool'][[col for col in subset.columns if col not in ['dataset', 'model']]]\n",
    "    \n",
    "    subset = subset[[col for col in subset.columns if col not in ['dataset', 'model']]]\n",
    "    \n",
    "    difference = (wavpool-subset)/subset\n",
    "    table.add_multicol_element(super_columns=[dataset], columns=difference.columns, title=dataset, rows_name=model_names, data_to_fill=np.round(difference.values, decimals=3))\n",
    "\n",
    "table.make()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Def make fractional difference \n",
    "\n",
    "table = Table([])\n",
    "\n",
    "frac_difference = pd.DataFrame()\n",
    "model = \"CNN\"\n",
    "results = []\n",
    "for dataset, dataset_name in zip([\"_MNIST\",\"FashionMNIST\", \"CIFAR\"], [\"MNIST\", \"FMNIST\", \"CIFAR-10\"]): \n",
    "\n",
    "    histories = read_history_json(model, dataset)\n",
    "    \n",
    "    val_acc = pd.DataFrame([history[f\"val_{TrainingMetrics.accuracy.__name__}\"] for history in histories]).mean(axis=1)\n",
    "    val = np.round(val_acc.mean(), 3)\n",
    "    errorbar = np.round(val_acc.std(), 3)\n",
    "\n",
    "    acc = f\"{val}$\\pm${errorbar}\"\n",
    "    print(acc)\n",
    "    val_roc = pd.DataFrame([history[f\"val_{TrainingMetrics.auc_roc.__name__}\"] for history in histories]).mean(axis=1)\n",
    "    val = np.round(val_roc.mean(axis=0), 3)\n",
    "    errorbar = np.round(val_roc.std(axis=0), 3)\n",
    "\n",
    "    roc = f\"{val}$\\pm${errorbar}\"\n",
    "    \n",
    "    n_params = \"ph\"\n",
    "\n",
    "    results.append([dataset_name, n_params, roc, acc])\n",
    "\n",
    "table.table_elements = Elements.singlerow_subtable(results)\n",
    "table.make()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
